{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\zippy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\zippy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\zippy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\zippy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\zippy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\zippy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import csv\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should transform data into a usable format \n",
    "def audioProcess(path):\n",
    "    data = pd.read_csv(path)\n",
    "    #get audio data from vect1 to vect148\n",
    "    audioData = data.loc[:, \"vect_1\":\"vect_148\"]\n",
    "    \n",
    "    # normalization\n",
    "    audioData=(audioData-audioData.mean())/audioData.std()\n",
    "    \n",
    "    return audioData.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should transform data into a usable format \n",
    "def textProcess(path):\n",
    "    data = pd.read_csv(path)\n",
    "    #get audio data from vect1 to vect148\n",
    "    textData = data.loc[:, \"tags\"]\n",
    "    \n",
    "    return textData.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should transform data into a usable format \n",
    "def labelProcess(path):\n",
    "    data = pd.read_csv(path)\n",
    "    #get classes\n",
    "    labels = data.loc[:,\"genre\"].values.tolist()\n",
    "    \n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toOneHot(classes, labels):\n",
    "    one_hot_labels = []\n",
    "\n",
    "    for label in labels:\n",
    "        one_hot_vector = [0] * len(classes)\n",
    "        one_hot_vector[classes.index(label)] = 1\n",
    "\n",
    "        one_hot_labels.append(one_hot_vector)\n",
    "    return one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(audioData, textData, trainLabel, model):\n",
    "    \n",
    "    batch_size = 32  #the number of data to feed into model per batch\n",
    "    num_epoch = 50  # go through your training data epoch times\n",
    "    \n",
    "    #callbacks stop training if val_loss is not improving.\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose = 1)]\n",
    "    \n",
    "    history = model.fit([audioData, textData], trainLabel, validation_split=0.2, epochs = num_epoch, batch_size=batch_size, verbose=1, callbacks = callbacks)\n",
    "                 \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(textData, trainLabel):\n",
    "    num_classes = len(trainLabel[0])  # total classes to train\n",
    "    \n",
    "    model1_in = Input(shape=(148, 1))\n",
    "    model1 = (Conv1D(128, 10,padding=\"same\", activation=\"relu\", kernel_initializer=\"random_uniform\"))(model1_in)\n",
    "    model1 = Dropout(0.5)(model1)\n",
    "    model1 = MaxPooling1D(pool_size=(2))(model1)\n",
    "    model1 = Conv1D(64, 10,padding=\"same\", activation=\"relu\", kernel_initializer=\"random_uniform\")(model1)\n",
    "    model1 = Dropout(0.5)(model1)\n",
    "    model1_out = Flatten()(model1)\n",
    "    \n",
    "    model2_in = Input(shape=textData.shape[1:])\n",
    "    \n",
    "    concatenated = concatenate([model1_out, model2_in])\n",
    "    out = Dense(num_classes, activation=\"softmax\", kernel_initializer=\"random_uniform\")(concatenated)\n",
    "    \n",
    "    merged_model = Model([model1_in, model2_in], out)\n",
    "    \n",
    "    #Define loss, optimizer, and metrics\n",
    "    merged_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return merged_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(testData, model):\n",
    "    prediction = model.predict(testData)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_label, prediction):\n",
    "    accuracy = metrics.accuracy_score(test_label, prediction)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainText = np.array(textProcess(r\"D:\\Unimelb\\Introduction to Machine Learning\\assignment2\\dataset\\dataset\\train_features.csv\"))\n",
    "validText= np.array(textProcess(r\"D:\\Unimelb\\Introduction to Machine Learning\\assignment2\\dataset\\dataset\\valid_features.csv\"))\n",
    "testText = np.array(textProcess(r\"D:\\Unimelb\\Introduction to Machine Learning\\assignment2\\dataset\\dataset\\test_features.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create BOW\n",
    "trainTxt = []\n",
    "validTxt = []\n",
    "testTxt = []\n",
    "for i in range(len(trainText)):\n",
    "    trainTxt.append(trainText[i].replace(\",\", \"\"))\n",
    "    \n",
    "for i in range(len(validText)):\n",
    "    validTxt.append(validText[i].replace(\",\", \"\"))   \n",
    "    \n",
    "for i in range(len(testText)):\n",
    "    testTxt.append(testText[i].replace(\",\", \"\"))   \n",
    "    \n",
    "vectorizer = CountVectorizer() \n",
    "trainVectors = vectorizer.fit_transform(trainTxt)\n",
    "validVectors = vectorizer.transform(validTxt)\n",
    "testVectors = vectorizer.transform(testTxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAudio = np.expand_dims(np.array(audioProcess(r\"D:\\Unimelb\\Introduction to Machine Learning\\assignment2\\dataset\\dataset\\train_features.csv\")), axis=2)\n",
    "validAudio = np.expand_dims(np.array(audioProcess(r\"D:\\Unimelb\\Introduction to Machine Learning\\assignment2\\dataset\\dataset\\valid_features.csv\")), axis=2)\n",
    "testAudio = np.expand_dims(np.array(audioProcess(r\"D:\\Unimelb\\Introduction to Machine Learning\\assignment2\\dataset\\dataset\\test_features.csv\")), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabel = labelProcess(r\"D:\\Unimelb\\Introduction to Machine Learning\\assignment2\\dataset\\dataset\\train_labels.csv\")\n",
    "validLabel = labelProcess(r\"D:\\Unimelb\\Introduction to Machine Learning\\assignment2\\dataset\\dataset\\valid_labels.csv\")\n",
    "#get classes\n",
    "classes = list(set(trainLabel))\n",
    "\n",
    "oneHotTrain = np.array(toOneHot(classes, trainLabel))\n",
    "oneHotvalid = np.array(toOneHot(classes, validLabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zippy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\zippy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 148, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 148, 128)     1408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 148, 128)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 74, 128)      0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 74, 64)       81984       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 74, 64)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4736)         0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 4827)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 9563)         0           flatten_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            76512       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 159,904\n",
      "Trainable params: 159,904\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models(trainVectors, oneHotTrain)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zippy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 6142 samples, validate on 1536 samples\n",
      "Epoch 1/50\n",
      "6142/6142 [==============================] - 4s 730us/step - loss: 1.3434 - acc: 0.5246 - val_loss: 1.1147 - val_acc: 0.6283\n",
      "Epoch 2/50\n",
      "6142/6142 [==============================] - 1s 232us/step - loss: 0.9853 - acc: 0.6589 - val_loss: 1.0628 - val_acc: 0.6315\n",
      "Epoch 3/50\n",
      "6142/6142 [==============================] - 1s 224us/step - loss: 0.8238 - acc: 0.7185 - val_loss: 0.9688 - val_acc: 0.6686\n",
      "Epoch 4/50\n",
      "6142/6142 [==============================] - 1s 220us/step - loss: 0.7044 - acc: 0.7613 - val_loss: 0.9620 - val_acc: 0.6686\n",
      "Epoch 5/50\n",
      "6142/6142 [==============================] - 1s 230us/step - loss: 0.6203 - acc: 0.8022 - val_loss: 0.9517 - val_acc: 0.6595\n",
      "Epoch 6/50\n",
      "6142/6142 [==============================] - 1s 235us/step - loss: 0.5536 - acc: 0.8295 - val_loss: 0.9134 - val_acc: 0.6888\n",
      "Epoch 7/50\n",
      "6142/6142 [==============================] - 1s 229us/step - loss: 0.4977 - acc: 0.8439 - val_loss: 0.9093 - val_acc: 0.6771\n",
      "Epoch 8/50\n",
      "6142/6142 [==============================] - 1s 227us/step - loss: 0.4459 - acc: 0.8702 - val_loss: 0.8989 - val_acc: 0.6862\n",
      "Epoch 9/50\n",
      "6142/6142 [==============================] - 1s 232us/step - loss: 0.4102 - acc: 0.8753 - val_loss: 0.9077 - val_acc: 0.6777\n",
      "Epoch 10/50\n",
      "6142/6142 [==============================] - 1s 231us/step - loss: 0.3688 - acc: 0.8979 - val_loss: 0.8979 - val_acc: 0.6836\n",
      "Epoch 11/50\n",
      "6142/6142 [==============================] - 1s 234us/step - loss: 0.3309 - acc: 0.9113 - val_loss: 0.9130 - val_acc: 0.6790\n",
      "Epoch 12/50\n",
      "6142/6142 [==============================] - 1s 225us/step - loss: 0.3046 - acc: 0.9184 - val_loss: 0.9047 - val_acc: 0.6862\n",
      "Epoch 13/50\n",
      "6142/6142 [==============================] - 1s 224us/step - loss: 0.2863 - acc: 0.9264 - val_loss: 0.9184 - val_acc: 0.6797\n",
      "Epoch 00013: early stopping\n",
      "Finish training\n"
     ]
    }
   ],
   "source": [
    "history = train(trainAudio, trainVectors, oneHotTrain, model)\n",
    "print(\"Finish training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 168us/step\n",
      "loss, accuracy: 1.004422158135308 0.7\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate([validAudio, validVectors], oneHotvalid)\n",
    "print(\"loss, accuracy:\", loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackID = pd.read_csv(r\"D:\\Unimelb\\Introduction to Machine Learning\\assignment2\\dataset\\dataset\\test_features.csv\").loc[:, \"trackID\"].values.tolist()\n",
    "prediction = predict([testAudio, testVectors], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction.tolist()\n",
    "results_name = []\n",
    "\n",
    "for result in prediction:\n",
    "    results_name.append(classes[result.index(max(result))])\n",
    "    \n",
    "result = list(zip(trackID,results_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_outPut.csv\", 'w', newline='') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerow([\"trackID\", \"genre\"])\n",
    "    writer.writerows(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
